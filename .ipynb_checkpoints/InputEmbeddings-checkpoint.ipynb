{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283a825a-8448-4e96-bb54-dfca2cd19aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0fdea83-0b8e-4c0b-9507-b5ef6d1ae91e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        #does not pass all input words with eachother. Each word goes through independantly\n",
    "        #and the output are the embeddings of the word. We want this because we do not \n",
    "        #want to concacenate the embeddings to the output nodes.\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) \n",
    "        #now takes in all embeddings of each word stretched out\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        self.tokens = {}\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        #embeds will be flattened matrix\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        #rectified relu to learn embeddings\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        #output is the log probablities of all vocabulary\n",
    "        return log_probs\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63bfd991-fc29-40b4-9c10-531edb2081aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3512\n",
      "Train Dataset size: 100\n",
      "Total Dictionary Size: 10,489\n",
      "Training Dictionary Size: 586\n",
      "Epoch: 0\n",
      "Total_Loss: 5902.9905116558075\n",
      "Epoch: 1\n",
      "Total_Loss: 4411.793348670006\n",
      "Epoch: 2\n",
      "Total_Loss: 3575.1542907953262\n",
      "Epoch: 3\n",
      "Total_Loss: 3001.015433639288\n",
      "Epoch: 4\n",
      "Total_Loss: 2472.4445091485977\n",
      "Epoch: 5\n",
      "Total_Loss: 1945.913971543312\n",
      "Epoch: 6\n",
      "Total_Loss: 1431.9736630246043\n",
      "Epoch: 7\n",
      "Total_Loss: 975.9797193184495\n",
      "Epoch: 8\n",
      "Total_Loss: 625.2487171627581\n",
      "Epoch: 9\n",
      "Total_Loss: 387.28769674524665\n"
     ]
    }
   ],
   "source": [
    "#file path to credit card csv file\n",
    "file_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\", \"mental_health.csv\")\n",
    "orig_dataset = pd.read_csv(file_path) #read csv file as pandas object\n",
    "orig_dataset = orig_dataset.to_numpy()\n",
    "print(\"Dataset size: \"+ str(len(orig_dataset)))\n",
    "dataset = orig_dataset[0:100] #use part of the dataset\n",
    "print(\"Train Dataset size: \"+ str(len(dataset)))\n",
    "minFreq = {} #word must appear n times to be added to dictionary\n",
    "dictionary = {} #relevant words in the dicationary\n",
    "index = 2\n",
    "for example in range(len(dataset)):\n",
    "    for cont_response in range(2):\n",
    "        if type(dataset[example][cont_response]) == float: #NaN values\n",
    "            continue\n",
    "        for word in dataset[example][cont_response].split():\n",
    "            if word not in minFreq:\n",
    "                minFreq[word]=1\n",
    "            else:\n",
    "                if minFreq[word]==3: #word needs to appear\n",
    "                    dictionary[word] = index\n",
    "                    index+=1\n",
    "                minFreq[word]+=1\n",
    "\n",
    "print( \"Total Dictionary Size: 10,489\")\n",
    "print(\"Training Dictionary Size: \" + str(index))\n",
    "\n",
    "CONTEXT_SIZE = 3 #look 3 words back to predict current word\n",
    "EMBEDDING_DIM = 252 #total embeddings for each word\n",
    "all_ngrams = [] #ngram setup -> [(['through', 'going', \"I'm\"], 'some')]\n",
    "for example in range(len(dataset)): \n",
    "    for cont_response in range(2): #context than response\n",
    "        if type(dataset[example][cont_response]) == float: #NaN values\n",
    "            continue\n",
    "        cur_Sentence = dataset[example][cont_response].split() #seperate by word\n",
    "        ngrams = [ #[(['through', 'going', \"I'm\"], 'some')]\n",
    "            ([cur_Sentence[i - j - 1] for j in range(CONTEXT_SIZE)],cur_Sentence[i])\n",
    "            for i in range(CONTEXT_SIZE, len(cur_Sentence))\n",
    "            ]\n",
    "        #append the grams to all_ngrams\n",
    "        for i in ngrams:\n",
    "            all_ngrams.append(i) \n",
    "loss_function = nn.NLLLoss() #loss layer\n",
    "model = NGramLanguageModeler(index, EMBEDDING_DIM, CONTEXT_SIZE) #intialize Ngram model\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "model.tokens = dictionary\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    print(\"Epoch: \"+ str(epoch))\n",
    "    maxFreq = 3 #max number of times a word can be trained\n",
    "    #dictionary to keep track of times word is trained. Will skip if words have been trained maxFreq times\n",
    "    maxFreqDict = {}\n",
    "    for context, target in all_ngrams:\n",
    "        #if unknown word, just don't train\n",
    "        if context[0] not in dictionary or context[1] not in dictionary or context[2] not in dictionary:\n",
    "                continue\n",
    "        if target not in dictionary:\n",
    "                continue\n",
    "        #add context words if not found in dict\n",
    "        if context[0] not in maxFreqDict:\n",
    "            maxFreqDict[context[0]] = 1\n",
    "        if context[1] not in maxFreqDict:\n",
    "            maxFreqDict[context[1]] = 1\n",
    "        #if both words have been trained equal to or more than maxFreq times, continue\n",
    "        #already has been trained enough\n",
    "        if maxFreqDict[context[0]] >= maxFreq and maxFreqDict[context[1]] >= maxFreq:\n",
    "            continue\n",
    "        #update how many times the context words have been trained\n",
    "        maxFreqDict[context[0]]+=1\n",
    "        maxFreqDict[context[1]]+=1\n",
    "            \n",
    "        #turn each word to an integer and wrapped in tensor so pass as an input to the model\n",
    "        context_idxs = torch.tensor([dictionary[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        #zero out gradients cause it accumulates\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "        #apply the loss function to the log probabilties with the correct target word\n",
    "        loss = loss_function(log_probs, torch.tensor([dictionary[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Total_Loss: {total_loss}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87bdd6f4-bc7f-44b2-8dd7-218d78a5437e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"embedding_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3d7463e-6ccc-4042-ae90-636c10dcaec6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7672e-01, -1.5192e-01, -5.1461e-01, -6.4002e-02,  9.4309e-01,\n",
      "         -1.4097e+00,  2.8258e-01,  2.0679e+00, -9.7824e-01, -8.4059e-01,\n",
      "          1.2134e+00,  4.1745e-01, -7.2366e-01, -9.7466e-01,  1.6613e-01,\n",
      "         -1.4812e+00, -1.0331e+00,  4.8142e-02,  2.7379e+00, -2.3871e-01,\n",
      "          1.5224e+00, -5.6099e-01,  1.3882e+00, -1.0950e+00, -1.2337e-01,\n",
      "         -1.0016e+00,  1.3851e-01,  1.4503e+00,  9.9192e-01,  2.1777e-01,\n",
      "          5.9040e-01, -1.4746e+00,  5.5005e-01, -1.0135e+00, -2.8678e-01,\n",
      "          5.7993e-01, -3.4451e-01, -4.6991e-01,  4.7323e-01, -5.9747e-01,\n",
      "         -1.1831e+00, -1.4838e+00, -2.2291e-01,  7.3458e-01, -8.9810e-01,\n",
      "         -1.1718e+00,  1.1870e+00,  6.4771e-01,  7.5589e-01,  8.2695e-01,\n",
      "         -1.2989e+00, -1.9237e+00,  5.4533e-01,  2.0857e+00,  8.1906e-01,\n",
      "          4.9261e-01,  1.1715e+00,  6.6621e-01, -9.0302e-01,  5.9374e-01,\n",
      "          3.0043e-01, -1.8857e+00, -3.0415e+00,  4.8082e-01, -3.6050e-01,\n",
      "         -4.6776e-01,  9.2219e-01,  7.6490e-02, -6.9975e-01,  1.4801e+00,\n",
      "         -9.2739e-01,  4.8467e-01, -8.2271e-01, -2.0613e-01, -6.9497e-01,\n",
      "          5.5718e-01,  1.2774e+00,  9.2500e-02, -6.1795e-01,  1.6905e-01,\n",
      "         -2.7775e-01,  1.5315e+00,  1.9536e-01,  4.8497e-01, -9.2258e-01,\n",
      "          4.7930e-01, -5.7748e-01, -5.3177e-01, -2.0880e+00, -4.1744e-01,\n",
      "          1.2795e+00,  7.5976e-01, -4.8252e-03,  1.0905e+00, -1.8104e+00,\n",
      "         -1.0060e+00,  5.3885e-01,  3.7964e-01,  2.2092e+00,  2.3360e-01,\n",
      "         -2.3952e-01,  1.2415e+00,  1.0946e+00,  2.0319e+00, -1.1295e+00,\n",
      "          4.6961e-01,  6.5697e-01,  1.4983e-01,  5.4587e-01, -1.5449e+00,\n",
      "         -3.5215e-01,  1.2391e+00,  2.7380e-01,  7.5423e-01, -4.1638e-01,\n",
      "          7.7397e-02,  3.1258e-01, -3.9589e-01,  1.0195e+00, -1.5499e+00,\n",
      "          2.4148e-01,  8.7064e-01,  1.2633e+00,  9.3147e-01, -1.1544e+00,\n",
      "          1.0567e+00, -4.0976e-02,  7.9724e-01, -5.0610e-01, -5.2331e-01,\n",
      "         -1.7824e+00,  9.3684e-01, -1.9067e+00,  1.4467e+00,  1.0173e+00,\n",
      "         -2.8363e-01,  3.2066e-02, -3.2412e-02,  5.6639e-01, -1.5928e+00,\n",
      "          1.2945e+00, -8.7121e-01,  1.0198e+00,  1.1967e+00,  2.5832e-01,\n",
      "         -1.4503e+00,  1.6113e+00,  2.7794e+00,  5.3549e-01,  1.6114e+00,\n",
      "          1.1323e-01,  1.2885e+00,  5.5855e-01,  9.8024e-01,  7.3750e-01,\n",
      "          4.6733e-01, -1.5246e+00,  3.5547e-02,  5.8004e-01, -1.9081e+00,\n",
      "          2.0704e+00, -2.0102e-03,  5.8576e-01,  8.2164e-01, -2.6669e-01,\n",
      "          1.2590e+00, -1.5141e-01,  1.0713e+00,  9.1798e-01,  1.4622e+00,\n",
      "          9.8907e-01, -1.4476e+00, -2.1425e+00, -6.7718e-02, -1.5794e+00,\n",
      "         -1.1171e+00, -9.7965e-02, -5.7355e-01,  1.1873e+00, -4.9614e-01,\n",
      "         -1.7283e-01, -2.4271e+00,  1.6964e+00, -1.7348e-02,  1.2467e+00,\n",
      "         -1.8684e+00,  5.9155e-02, -4.0006e-01,  9.4681e-02,  9.2456e-01,\n",
      "         -1.8605e+00,  1.7694e+00, -9.4054e-01, -1.8710e+00, -6.9148e-01,\n",
      "          1.5195e+00,  2.5626e-03, -4.6842e-01, -7.6608e-02, -2.1489e-01,\n",
      "          1.1655e-01, -9.4744e-01,  2.8553e-01,  6.9044e-01,  3.0768e-01,\n",
      "         -1.2576e-01, -5.3208e-01,  5.4499e-01, -6.3467e-01,  3.1383e+00,\n",
      "         -1.6647e+00, -2.2643e-01, -7.8833e-01, -2.8996e-01, -5.1590e-02,\n",
      "          6.5474e-01, -5.4590e-02, -6.0686e-01,  1.4686e+00, -1.4946e+00,\n",
      "          6.7769e-01,  6.5854e-01, -5.8446e-01, -1.1380e+00,  1.3579e-01,\n",
      "         -1.7148e+00,  1.7820e-01, -3.3701e-01, -2.0313e-01, -2.8571e-01,\n",
      "         -2.5494e+00,  3.0511e-01, -5.1331e-01, -6.8318e-01,  1.8629e-01,\n",
      "          5.0622e-01,  4.0406e-01, -1.6195e+00, -9.0656e-01, -3.9169e-01,\n",
      "          5.9497e-01,  1.7574e+00, -8.8948e-01,  4.9998e-02, -8.8869e-01,\n",
      "         -5.7081e-01, -1.8015e+00, -4.4497e-01,  6.5934e-01,  2.9457e-01,\n",
      "         -3.4676e-01, -9.9951e-01]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.embeddings(torch.tensor([0])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
