{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "283a825a-8448-4e96-bb54-dfca2cd19aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0fdea83-0b8e-4c0b-9507-b5ef6d1ae91e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        #does not pass all input words with eachother. Each word goes through independantly\n",
    "        #and the output are the embeddings of the word. We want this because we do not \n",
    "        #want to concacenate the embeddings to the output nodes.\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) \n",
    "        #now takes in all embeddings of each word stretched out\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        self.tokens = {}\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        #embeds will be flattened matrix\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        #rectified relu to learn embeddings\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        #output is the log probablities of all vocabulary\n",
    "        return log_probs\n",
    "    def multiply_embedding_weights(self):\n",
    "        # Multiply the weights of the embedding layer by sqrt(embedding_dim)\n",
    "        self.embeddings.weight.data = self.embeddings.weight.data * (self.embedding_dim ** 0.5)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63bfd991-fc29-40b4-9c10-531edb2081aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3512\n",
      "Train Dataset size: 100\n",
      "Total Dictionary Size: 10,489\n",
      "Training Dictionary Size: 587\n",
      "Epoch: 0\n",
      "Total_Loss: 5885.7825446128845\n",
      "Epoch: 1\n",
      "Total_Loss: 4376.34392029047\n",
      "Epoch: 2\n",
      "Total_Loss: 3540.24500015378\n",
      "Epoch: 3\n",
      "Total_Loss: 2963.5320244431496\n",
      "Epoch: 4\n",
      "Total_Loss: 2429.867686033249\n",
      "Epoch: 5\n",
      "Total_Loss: 1898.4305011332035\n",
      "Epoch: 6\n",
      "Total_Loss: 1384.8991828262806\n",
      "Epoch: 7\n",
      "Total_Loss: 940.1817636080086\n",
      "Epoch: 8\n",
      "Total_Loss: 602.8155143596232\n",
      "Epoch: 9\n",
      "Total_Loss: 374.5147422272712\n"
     ]
    }
   ],
   "source": [
    "#file path to credit card csv file\n",
    "file_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\", \"mental_health.csv\")\n",
    "orig_dataset = pd.read_csv(file_path) #read csv file as pandas object\n",
    "orig_dataset = orig_dataset.to_numpy()\n",
    "print(\"Dataset size: \"+ str(len(orig_dataset)))\n",
    "dataset = orig_dataset[0:100] #use part of the dataset\n",
    "print(\"Train Dataset size: \"+ str(len(dataset)))\n",
    "minFreq = {} #word must appear n times to be added to dictionary\n",
    "dictionary = {} #relevant words in the dicationary\n",
    "index = 3\n",
    "for example in range(len(dataset)):\n",
    "    for cont_response in range(2):\n",
    "        if type(dataset[example][cont_response]) == float: #NaN values\n",
    "            continue\n",
    "        for word in dataset[example][cont_response].split():\n",
    "            if word not in minFreq:\n",
    "                minFreq[word]=1\n",
    "            else:\n",
    "                if minFreq[word]==3: #word needs to appear\n",
    "                    dictionary[word] = index\n",
    "                    index+=1\n",
    "                minFreq[word]+=1\n",
    "\n",
    "print( \"Total Dictionary Size: 10,489\")\n",
    "print(\"Training Dictionary Size: \" + str(index))\n",
    "\n",
    "CONTEXT_SIZE = 3 #look 3 words back to predict current word\n",
    "EMBEDDING_DIM = 252 #total embeddings for each word\n",
    "all_ngrams = [] #ngram setup -> [(['through', 'going', \"I'm\"], 'some')]\n",
    "for example in range(len(dataset)): \n",
    "    for cont_response in range(2): #context than response\n",
    "        if type(dataset[example][cont_response]) == float: #NaN values\n",
    "            continue\n",
    "        cur_Sentence = dataset[example][cont_response].split() #seperate by word\n",
    "        ngrams = [ #[(['through', 'going', \"I'm\"], 'some')]\n",
    "            ([cur_Sentence[i - j - 1] for j in range(CONTEXT_SIZE)],cur_Sentence[i])\n",
    "            for i in range(CONTEXT_SIZE, len(cur_Sentence))\n",
    "            ]\n",
    "        #append the grams to all_ngrams\n",
    "        for i in ngrams:\n",
    "            all_ngrams.append(i) \n",
    "loss_function = nn.NLLLoss() #loss layer\n",
    "model = NGramLanguageModeler(index, EMBEDDING_DIM, CONTEXT_SIZE) #intialize Ngram model\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "model.tokens = dictionary\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    print(\"Epoch: \"+ str(epoch))\n",
    "    maxFreq = 3 #max number of times a word can be trained\n",
    "    #dictionary to keep track of times word is trained. Will skip if words have been trained maxFreq times\n",
    "    maxFreqDict = {}\n",
    "    for context, target in all_ngrams:\n",
    "        #if unknown word, just don't train\n",
    "        if context[0] not in dictionary or context[1] not in dictionary or context[2] not in dictionary:\n",
    "                continue\n",
    "        if target not in dictionary:\n",
    "                continue\n",
    "        #add context words if not found in dict\n",
    "        if context[0] not in maxFreqDict:\n",
    "            maxFreqDict[context[0]] = 1\n",
    "        if context[1] not in maxFreqDict:\n",
    "            maxFreqDict[context[1]] = 1\n",
    "        #if both words have been trained equal to or more than maxFreq times, continue\n",
    "        #already has been trained enough\n",
    "        if maxFreqDict[context[0]] >= maxFreq and maxFreqDict[context[1]] >= maxFreq:\n",
    "            continue\n",
    "        #update how many times the context words have been trained\n",
    "        maxFreqDict[context[0]]+=1\n",
    "        maxFreqDict[context[1]]+=1\n",
    "            \n",
    "        #turn each word to an integer and wrapped in tensor so pass as an input to the model\n",
    "        context_idxs = torch.tensor([dictionary[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        #zero out gradients cause it accumulates\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "        #apply the loss function to the log probabilties with the correct target word\n",
    "        loss = loss_function(log_probs, torch.tensor([dictionary[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Total_Loss: {total_loss}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87bdd6f4-bc7f-44b2-8dd7-218d78a5437e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.multiply_embedding_weights()\n",
    "torch.save(model.state_dict(), \"embedding_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3d7463e-6ccc-4042-ae90-636c10dcaec6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -4.7948, -26.4644,  -5.0079,  17.7587,   1.4938, -11.4514,   6.3949,\n",
      "          11.3483,  -1.3144,  -5.3507, -19.4646,   0.7455,  10.1871,  17.8926,\n",
      "         -21.9235,  -2.8438,   0.4512,   2.2330,   8.8070,  10.1678, -22.3537,\n",
      "          -9.1823, -30.1354,  -3.6915, -11.9838,   0.5091,  -4.1681,  25.6648,\n",
      "           7.0265, -15.2028, -45.1531,  35.9497,  -1.3178,  -8.0810,  15.1297,\n",
      "         -16.1959,  36.2009, -20.9072, -24.2222, -20.8557, -21.9368,  -2.2843,\n",
      "         -30.8839,  13.5183,   0.1884,  -2.0043,  -6.4819,  -1.5034,  16.4114,\n",
      "         -10.9946,   2.2216,   6.7104, -28.1329,  -5.4743,   2.5739,  22.4210,\n",
      "          -4.0999,  -3.9907, -39.5984,  12.9918,  22.9995,  12.4905,  15.4697,\n",
      "           1.3892,   0.5988,  10.4520,  58.6825, -12.1076,   2.5667, -15.0884,\n",
      "           2.7434,  -2.2431,  35.6010,   6.0854,  -5.4732,  25.5039,   0.6284,\n",
      "           3.1580,   6.1247,   7.1890,   9.6024,  -3.5268, -20.0814, -15.8626,\n",
      "           3.3456,  -8.0265, -13.1466,   0.2914,   5.3813,   4.3884,   8.8396,\n",
      "           2.1914,  -1.2993, -21.8177, -19.6843,  13.9380,   8.3960, -31.0945,\n",
      "         -19.0838,   1.6412,   2.0015,   2.2701,   6.8170,  35.2535,  -7.0920,\n",
      "         -11.3812,  12.7942, -13.0682,  -0.2249,   1.9005,  -9.7034,  -0.7498,\n",
      "          19.9660, -17.7726,  -1.9196, -24.5661,  -2.6432,  -0.6368,   2.4496,\n",
      "          -7.0543,   1.8186,   3.3341,   7.8638,   5.9271,   2.1619, -20.7471,\n",
      "           0.3080,  28.4788,  18.8966, -16.8414,  13.0812,  -0.9765,  -3.4517,\n",
      "         -17.1910,  -4.0505,  -1.3349,  -3.8964,  -5.3104,  -4.8031,  19.8893,\n",
      "          -6.4820,   0.6697,  38.1430,   7.6459,  13.2647,   5.7428,  -1.3682,\n",
      "         -13.9619, -15.4954,  -5.5170,  -3.5257,  -7.6360,   4.1612,  16.9677,\n",
      "          17.8806, -15.6440,  18.1397,   7.9175, -16.9978,   1.7124,   2.7265,\n",
      "           4.8623,  15.6329,  28.3586, -13.3878, -11.2114, -28.6782,  12.5525,\n",
      "          11.0870,  10.1892,  21.2750,  25.1210,   9.3588,   5.0976,   0.7558,\n",
      "         -11.1469,  11.7437,  15.6229,  17.2303,   9.7676, -18.4100,   8.3435,\n",
      "          11.8365,  -5.8700,  -5.8716,  -9.9114,  -1.7017,  -9.3454, -10.8871,\n",
      "           7.8839, -13.6863,   6.3671,   8.9110,  -6.1593, -16.0406,  23.1936,\n",
      "          24.4072, -15.8751,   2.7961, -20.7008,  -8.8156, -13.4511,  30.6121,\n",
      "           1.2034,   8.8445,  25.5878, -11.7613, -18.9298,  17.5930,   1.6981,\n",
      "          -8.1605,  11.3530,  -8.5368, -15.2501,  21.8533,   6.6167,   6.5460,\n",
      "          11.8083,   1.3843,  12.9728,  13.0051,  17.8763,   5.8603,   6.4250,\n",
      "         -19.5081,  -0.5483,  27.5715,  -6.2804,  -8.0879,  15.2726,  22.4971,\n",
      "          -7.5918,  -7.0709,  26.3227,   1.6278,  16.6534,   0.0678,  -5.9933,\n",
      "          10.3811,  -5.8067, -10.5803,  -3.1897,   9.1102,  -6.2861,  -8.1545,\n",
      "          10.9636, -14.8567,   2.5405,   3.2641,   7.5660,  -9.4742,   3.2051]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.embeddings(torch.tensor([0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665631ae-ced6-46e4-98f6-fd8a159109f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Embedding.forward() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39membeddings() \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model)\n\u001b[1;32m      2\u001b[0m json\u001b[38;5;241m.\u001b[39mdump(model\u001b[38;5;241m.\u001b[39mtokens, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Embedding.forward() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "json.dump(model.tokens, open(\"tokens.txt\",'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
