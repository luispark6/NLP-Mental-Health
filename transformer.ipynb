{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bca86dc3-6a8c-46f6-a249-4a7fdcb4acee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 520, 252])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "from torch import nn, Tensor\n",
    "\n",
    "MAX_LENGTH = 520\n",
    "tokens = json.load(open(\"tokens.txt\"))\n",
    "model = torch.load(\"embedding_model\")\n",
    "file_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\", \"mental_health.csv\")\n",
    "orig_dataset = pd.read_csv(file_path)\n",
    "orig_dataset = orig_dataset.to_numpy()\n",
    "trainingSet =  orig_dataset[np.random.choice(orig_dataset.shape[0], 4, replace=True)] #extract training set\n",
    "contextSet = [trainingSet[i][0] for i in range(len(trainingSet))] \n",
    "responseSet = [trainingSet[i][1] for i in range(len(trainingSet))]\n",
    "#tokenizing the context and response set, also 0 is special token for unknown word\n",
    "contextSet_tokenized = [[tokens[word] if word in tokens else 0 for word in example.split()] \n",
    "                         for example in contextSet ]\n",
    "responseSet_tokenized = [[tokens[word] if word in tokens else 0 for word in example.split()] \n",
    "                         for example in responseSet ]\n",
    "\n",
    "#convert token to input embedding for context and response set filled with padding\n",
    "#tokens if end of sentence. 1 is special token for padding \n",
    "contextSet_embedding = []        \n",
    "for context in contextSet_tokenized:\n",
    "    contextEmbedding = []\n",
    "    for i in range(MAX_LENGTH):\n",
    "        if i>= len(context):\n",
    "            contextEmbedding.append(model[\"embeddings.weight\"][1])\n",
    "            continue\n",
    "        contextEmbedding.append(model[\"embeddings.weight\"][context[i]])\n",
    "    contextEmbedding = torch.stack(contextEmbedding)\n",
    "    contextSet_embedding.append(contextEmbedding[:])\n",
    "\n",
    "contextSet_embedding = torch.stack(contextSet_embedding)\n",
    "\n",
    "responseSet_embedding = []        \n",
    "for response in responseSet_tokenized:\n",
    "    responseEmbedding = []\n",
    "    for i in range(MAX_LENGTH):\n",
    "        if i>= len(response):\n",
    "            responseEmbedding.append(model[\"embeddings.weight\"][1])\n",
    "            continue\n",
    "        responseEmbedding.append(model[\"embeddings.weight\"][response[i]])\n",
    "    responseEmbedding = torch.stack(responseEmbedding)\n",
    "    responseSet_embedding.append(responseEmbedding[:])\n",
    "    \n",
    "responseSet_embedding = torch.stack(responseSet_embedding)\n",
    "print(responseSet_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ba420137-3b54-46c9-83a5-84b855b7a7ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "37b740b8-1a7c-4354-b055-ca984b9e2779",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0000,  0.6529, -0.4049,  ..., -0.3518,  0.7513,  2.7533],\n",
       "         [-0.9623, -0.9468,  0.0000,  ...,  0.1233, -0.4650,  1.2283],\n",
       "         [ 0.6168,  2.7969, -1.3155,  ...,  1.8697, -0.9027, -0.1001],\n",
       "         ...,\n",
       "         [-0.4917,  0.4138,  1.2308,  ...,  0.4614, -1.6518,  0.2978],\n",
       "         [-0.4917,  0.4138,  1.2308,  ...,  0.4614, -1.6518,  0.2978],\n",
       "         [-0.4917,  0.4138,  1.2308,  ...,  0.4614, -1.6518,  0.2978]],\n",
       "\n",
       "        [[-0.0273, -1.4576,  0.9074,  ...,  0.1233, -0.4649,  1.2283],\n",
       "         [ 1.3544,  1.4590, -0.0797,  ...,  1.8897,  0.7357, -0.4069],\n",
       "         [ 0.9604,  1.1203, -0.0798,  ...,  1.3011,  0.2714,  1.9126],\n",
       "         ...,\n",
       "         [ 0.4433, -0.0969,  2.1212,  ...,  0.4614, -1.6516,  0.2978],\n",
       "         [ 0.4433, -0.0000,  2.1212,  ...,  0.4614, -1.6516,  0.2978],\n",
       "         [ 0.4433, -0.0969,  2.1212,  ...,  0.4614, -1.6516,  0.2978]],\n",
       "\n",
       "        [[ 0.4201, -0.0000, -0.0000,  ...,  0.0664,  1.2768,  0.2659],\n",
       "         [ 0.0000,  0.6150, -0.0631,  ...,  0.4671, -0.5631,  0.0000],\n",
       "         [ 0.0480, -2.5203,  1.0823,  ...,  0.1233, -0.4648,  1.2283],\n",
       "         ...,\n",
       "         [ 0.5186, -1.1597,  0.0000,  ...,  0.4614, -1.6515,  0.0000],\n",
       "         [ 0.5186, -1.1597,  2.2961,  ...,  0.4614, -1.6515,  0.2978],\n",
       "         [ 0.5186, -1.1597,  2.2961,  ...,  0.4614, -1.6515,  0.2978]],\n",
       "\n",
       "        [[-0.8798, -0.0000,  0.7977,  ...,  0.9271, -0.1661, -0.1093],\n",
       "         [ 0.7862, -0.0000,  0.1491,  ...,  0.0353,  0.7114, -0.1167],\n",
       "         [ 0.0000, -1.1831,  0.3724,  ...,  3.3717, -0.3085,  2.0191],\n",
       "         ...,\n",
       "         [-0.3349, -1.7973,  1.6150,  ...,  0.4614, -1.6514,  0.0000],\n",
       "         [-0.3349, -1.7973,  1.6150,  ...,  0.4614, -1.6514,  0.2978],\n",
       "         [-0.3349, -1.7973,  1.6150,  ...,  0.4614, -1.6514,  0.2978]]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = PositionalEncoding(252, max_len = MAX_LENGTH)\n",
    "pe.forward(contextSet_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
